{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from preprocessing import *\n",
    "\n",
    "from scipy.sparse import find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../data/ntup/partGun_PDGid15_x1000_Pt3.0To100.0_NTUP_1.root'\n",
    "rootfile = uproot.open(fname)['ana']['hgc']\n",
    "figs = []\n",
    "\n",
    "preprocessing_algo = make_graph_etaphi\n",
    "grouping_algo = 'knn' #or 'kdtree'\n",
    "preprocessing_args= dict(k=4)\n",
    "#preprocessing_args= dict(r = 0.07) #if algo == 'kdtree'\n",
    "layer_norm = 150 #only used for etaphi, no effect for other preprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHist(axes, data, xlabel, ylabel, title, Nbins = 100, range=None, xlog=False, ylog=False):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    if xlog:\n",
    "        axes.set_xscale('log')\n",
    "        Nbins = np.logspace(np.log10(data.min()),np.log10(data.max()),Nbins)\n",
    "    return axes.hist(data, bins=Nbins, range=range, histtype='step', log=ylog); \n",
    "    \n",
    "def plotHist_absxlog(axes, data, xlabel, ylabel, title, Nbins = 100, ylog=False):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    axes.set_xscale('log')\n",
    "    Nbins = np.logspace(np.log10(np.abs(data).min()),np.log10(np.abs(data).max()),Nbins)\n",
    "    axes.hist(data, bins=Nbins, histtype='step', log=ylog); \n",
    "    \n",
    "def plotHist_layers(data, ylabel, title, xlabel=\"Layer\", log=True):\n",
    "    fig,axes = plt.subplots(figsize=(10, 7));\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_xticks(np.arange(53)+0.5, minor=True)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_title(title)\n",
    "    axes.hist(data, range=(0,60), bins=np.arange(62)-0.5, log=log, histtype='step', linewidth = '1.5');\n",
    "    plt.grid(True, which='minor', axis='x', linewidth='0.5')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rechit = rootfile.arrays([b'rechit_thickness', b'rechit_energy',  b'rechit_layer',  b'rechit_time', \\\n",
    "                          b'rechit_x', b'rechit_y', b'rechit_z', b'rechit_eta', b'rechit_phi'])\n",
    "rechit[b'rechit_x'].content[rechit[b'rechit_z'].content < 0] *= -1\n",
    "NEvents = rechit[b'rechit_z'].shape[0]\n",
    "simcluster = rootfile.arrays([b'simcluster_hits_indices',  b'simcluster_energy', b'simcluster_eta', b'simcluster_phi', b'simcluster_layers', b'simcluster_pid'])\n",
    "#simcluster = rootfile.arrays([b'simcluster_hits_indices',  b'simcluster_energy', b'simcluster_eta', b'simcluster_phi', b'simcluster_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_indices = awkward.fromiter(simcluster[b'simcluster_hits_indices'])\n",
    "valid_sim_indices = sim_indices[sim_indices > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcluster_rechit_cut = 3 #min no. of rechits in simcluster requirement (exclusive)\n",
    "simcluster_mask = awkward.JaggedArray.fromcounts(valid_sim_indices.counts,valid_sim_indices.flatten().counts > simcluster_rechit_cut)\n",
    "simcluster_mask = simcluster_mask & (simcluster[b'simcluster_energy'] > 1.0)\n",
    "valid_sim_indices = valid_sim_indices[simcluster_mask]\n",
    "for key, value in simcluster.items():\n",
    "    if (key == b'simcluster_hits_indices'): continue\n",
    "    simcluster[key] = awkward.fromiter(value)[simcluster_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sim_indices_eventlevel = valid_sim_indices.flatten(1)\n",
    "valid_sim_indices_eventlevel = awkward.fromiter(map(np.unique, valid_sim_indices_eventlevel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simmatched_rechit = {}\n",
    "for key, value in rechit.items():\n",
    "    simmatched_rechit[key] = value[valid_sim_indices_eventlevel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrap_into_simcluster_structure(filelevel_array):\n",
    "    return awkward.JaggedArray.fromcounts(valid_sim_indices.counts,\\\n",
    "        (awkward.JaggedArray.fromcounts(valid_sim_indices.content.counts, filelevel_array)))\n",
    "\n",
    "rechit_simcluster = {}\n",
    "select_rechit_simcluster = [b'rechit_energy', b'rechit_layer', b'rechit_eta', b'rechit_phi']\n",
    "for key, value in rechit.items():\n",
    "    if key not in select_rechit_simcluster: continue\n",
    "    rechit_simcluster[key] = value[valid_sim_indices.flatten(1)]\n",
    "    rechit_simcluster[key] = rewrap_into_simcluster_structure(rechit_simcluster[key].content)\n",
    "    \n",
    "#corrected_rechit_simcluster_energy = rechit_simcluster[b'rechit_energy'] * rewrap_into_simcluster_structure(np.take(absorber_weights,rechit_simcluster[b'rechit_layer'].content.content))\n",
    "corrected_rechit_simcluster_energy = rechit_simcluster[b'rechit_energy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No. of rechits in Preprocessed Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_clusters_pos = []\n",
    "preprocessed_clusters_neg = []\n",
    "\n",
    "preprocessed_clusters_pos_Nedges = []\n",
    "preprocessed_clusters_neg_Nedges = []\n",
    "\n",
    "for ievt in tqdm(range(NEvents)):\n",
    "    g_pos = preprocessing_algo(rechit, valid_sim_indices, ievt = ievt, mask = rechit[b'rechit_z'][ievt] > 0,\n",
    "                                   layered_norm = layer_norm, algo=grouping_algo, preprocessing_args=preprocessing_args)\n",
    "    nx_graph_pos = nx.Graph()\n",
    "    list_tmp = list(zip(find(g_pos.Ri)[0], find(g_pos.Ro)[0]))\n",
    "    nx_graph_pos.add_edges_from(list_tmp)\n",
    "    preprocessed_clusters_pos.append(awkward.fromiter(nx.connected_components(nx_graph_pos)))\n",
    "    preprocessed_clusters_pos_Nedges.append(len(list_tmp))\n",
    "    \n",
    "    g_neg = preprocessing_algo(rechit, valid_sim_indices, ievt = ievt, mask = rechit[b'rechit_z'][ievt] < 0,\n",
    "                                   layered_norm = layer_norm, algo=grouping_algo, preprocessing_args=preprocessing_args)\n",
    "    nx_graph_neg = nx.Graph()\n",
    "    list_tmp = list(zip(find(g_neg.Ri)[0], find(g_neg.Ro)[0]))\n",
    "    nx_graph_neg.add_edges_from(list_tmp)\n",
    "    preprocessed_clusters_neg.append(awkward.fromiter(nx.connected_components(nx_graph_neg)))\n",
    "    preprocessed_clusters_neg_Nedges.append(len(list_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_clusters_pos = awkward.fromiter(preprocessed_clusters_pos)\n",
    "preprocessed_clusters_neg = awkward.fromiter(preprocessed_clusters_neg)\n",
    "#preprocessed_clusters_pos and preprocessed_clusters_neg are ids (within each pos/neg event) of rechits in each cluster\n",
    "\n",
    "def rewrap_into_eventCluster_structure(filelevel_array, target_structure):\n",
    "    return awkward.JaggedArray.fromcounts(target_structure.counts,\\\n",
    "        (awkward.JaggedArray.fromcounts(target_structure.flatten(0).counts, filelevel_array)))\n",
    "\n",
    "rechit_idx_map_pos = awkward.fromiter(map(np.where, (rechit[b'rechit_z'] > 0))).flatten()\n",
    "rechit_idx_map_neg = awkward.fromiter(map(np.where, (rechit[b'rechit_z'] < 0))).flatten()\n",
    "#map from pos/neg id to event-level id\n",
    "\n",
    "preprocessed_clusters_pos_gid = rewrap_into_eventCluster_structure(rechit_idx_map_pos[preprocessed_clusters_pos.flatten(1)].flatten(),\\\n",
    "                                  target_structure=preprocessed_clusters_pos)\n",
    "preprocessed_clusters_neg_gid = rewrap_into_eventCluster_structure(rechit_idx_map_neg[preprocessed_clusters_neg.flatten(1)].flatten(),\\\n",
    "                                  target_structure=preprocessed_clusters_neg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To reproduce the awkward array indexing bug:\n",
    "# Comment out the last two lines in previous cell and run:\n",
    "\n",
    "b = awkward.fromiter(preprocessed_clusters_pos[:2])\n",
    "a = b.max()[0]\n",
    "print(np.array_equal(a,b[0].max()), np.where(a!=b[0].max()))\n",
    "print(np.array_equal(a,b.max(regularaxis=0)[0]), np.where(a!=b.max(regularaxis=0)[0]))\n",
    "print(np.array_equal(a,b.max()[0]), np.where(a!=b.max()[0]))\n",
    "\n",
    "b = awkward.fromiter(preprocessed_clusters_pos[:3])\n",
    "a = b.max()[0]\n",
    "print(np.array_equal(a,b[0].max()), np.where(a!=b[0].max()))\n",
    "print(np.array_equal(a,b.max(regularaxis=0)[0]), np.where(a!=b.max(regularaxis=0)[0]))\n",
    "print(np.array_equal(a,b.max()[0]), np.where(a!=b.max()[0]))\n",
    "\n",
    "#output:\n",
    "#True (array([], dtype=int64),)\n",
    "#True (array([], dtype=int64),)\n",
    "#True (array([], dtype=int64),)\n",
    "\n",
    "#False (array([519]),)\n",
    "#True (array([], dtype=int64),)\n",
    "#True (array([], dtype=int64),)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Also, preprocessed_clusters_pos[0].flatten() != preprocessed_clusters_pos[0].content\n",
    "# preprocessed_clusters_pos[0].flatten() is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_clusters_counts = np.concatenate([preprocessed_clusters_pos_gid.flatten().counts, \\\n",
    "                                               preprocessed_clusters_neg_gid.flatten().counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(figsize=(12, 7));\n",
    "plotHist(axes, preprocessed_clusters_counts, \"Rechits\", \"Preprocessed Clusters\",\\\n",
    "         \"No. of Rechits in Preprocessed Clusters\", Nbins = 100, xlog=True, ylog=True)\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No. of Edges in Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(figsize=(12, 7));\n",
    "preprocessed_clusters_Nedges = np.concatenate((preprocessed_clusters_pos_Nedges, preprocessed_clusters_neg_Nedges))\n",
    "plotHist(axes, preprocessed_clusters_Nedges, \"N Edges\", \"Events\",\\\n",
    "         \"No. of Edges in Events\", Nbins = 100, xlog=False, ylog=True)\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of Corrected Energy of Rechits in each Preprocessed Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rechit_energy_corrected = rechit[b'rechit_energy'] * \\\n",
    "#    awkward.JaggedArray.fromcounts(rechit[b'rechit_energy'].counts,\\\n",
    "#                                   np.take(absorber_weights,rechit[b'rechit_layer'].flatten()))\n",
    "\n",
    "rechit_energy_corrected = rechit[b'rechit_energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rechit_energy_preprocessed_cluster_pos = rewrap_into_eventCluster_structure(rechit_energy_corrected[preprocessed_clusters_pos_gid.flatten(1)].flatten(),\\\n",
    "                                   preprocessed_clusters_pos_gid).flatten(0)\n",
    "rechit_energy_preprocessed_cluster_neg = rewrap_into_eventCluster_structure(rechit_energy_corrected[preprocessed_clusters_neg_gid.flatten(1)].flatten(),\\\n",
    "                                   preprocessed_clusters_neg_gid).flatten(0)\n",
    "\n",
    "rechit_energy_sum_preprocessed_cluster = np.concatenate([rechit_energy_preprocessed_cluster_pos.sum(), rechit_energy_preprocessed_cluster_neg.sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,5));\n",
    "ax1 = fig.add_subplot(121);\n",
    "plotHist(ax1, rechit_energy_sum_preprocessed_cluster, \"Sum of Energy of Rechits / GeV\", \"Preprocessed Clusters\",\\\n",
    "         \"Sum of Energy of Rechits in each Preprocessed Cluster\", range=(rechit_energy_sum_preprocessed_cluster.min(), rechit_energy_sum_preprocessed_cluster.max()), Nbins = 100, xlog=False, ylog=True)\n",
    "ax2 = fig.add_subplot(122);\n",
    "plotHist(ax2, rechit_energy_sum_preprocessed_cluster, \"Sum of Energy of Rechits / GeV\", \"Preprocessed Clusters\",\\\n",
    "         \"Sum of Energy of Rechits in each Preprocessed Cluster\", Nbins = 100, xlog=True, ylog=True)\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed Cluster - First Layer Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rechit_layer_preprocessed_cluster_pos = rewrap_into_eventCluster_structure((rechit[b'rechit_layer'][preprocessed_clusters_pos_gid.flatten(1)]).flatten(),\\\n",
    "                                   target_structure=preprocessed_clusters_pos).flatten(0)\n",
    "rechit_layer_preprocessed_cluster_neg = rewrap_into_eventCluster_structure((rechit[b'rechit_layer'][preprocessed_clusters_neg_gid.flatten(1)]).flatten(),\\\n",
    "                                   target_structure=preprocessed_clusters_neg).flatten(0)\n",
    "rechit_layer_preprocessed_cluster = awkward.JaggedArray.concatenate([rechit_layer_preprocessed_cluster_pos,\\\n",
    "                                                                    rechit_layer_preprocessed_cluster_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs.append(plotHist_layers(rechit_layer_preprocessed_cluster.min(),\\\n",
    "                            \"Preprocessed Cluster\", \"Preprocessed Cluster - First Layer Number\", xlabel= \"First Layer Number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed Cluster - Last Layer Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figs.append(plotHist_layers(rechit_layer_preprocessed_cluster.max(),\\\n",
    "                            \"Preprocessed Cluster\", \"Preprocessed Cluster - Last Layer Number\", xlabel= \"Last Layer Number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rechit Multiplicity in Greatest Intersection\n",
    "A simcluster's \"Greatest Intersection\" is defined as the largest intersection of rechits between this simcluster and any preprocessed cluster (on pos/neg endcap respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_row(row):\n",
    "    row = row.tolist()\n",
    "    return np.intersect1d(row[0], row[1])\n",
    "\n",
    "def intersect_table(awkward_table):\n",
    "    return map(intersect_row, awkward_table)\n",
    "\n",
    "intersection_pos = awkward.fromiter(map(intersect_table, valid_sim_indices[simcluster[b'simcluster_eta']>0].cross(preprocessed_clusters_pos_gid)))\n",
    "intersection_neg = awkward.fromiter(map(intersect_table, valid_sim_indices[simcluster[b'simcluster_eta']<0].cross(preprocessed_clusters_neg_gid)))\n",
    "\n",
    "intersection_pos = awkward.JaggedArray.fromcounts(valid_sim_indices[simcluster[b'simcluster_eta']>0].counts,\\\n",
    "    awkward.JaggedArray.fromcounts(np.repeat(preprocessed_clusters_pos_gid.counts, valid_sim_indices[simcluster[b'simcluster_eta']>0].counts), \\\n",
    "                       intersection_pos.flatten()))\n",
    "\n",
    "intersection_neg = awkward.JaggedArray.fromcounts(valid_sim_indices[simcluster[b'simcluster_eta']<0].counts,\\\n",
    "    awkward.JaggedArray.fromcounts(np.repeat(preprocessed_clusters_neg_gid.counts, valid_sim_indices[simcluster[b'simcluster_eta']<0].counts), \\\n",
    "                       intersection_neg.flatten()))\n",
    "\n",
    "#structure:\n",
    "#intersection_pos/neg[event idx][simcluster idx (for pos/neg respectively)][idx of preprocessed cluster(for pos/neg respectively)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcluster_energy_pos_neg = np.concatenate([simcluster[b'simcluster_energy'][simcluster[b'simcluster_eta']>0].flatten(),\\\n",
    "                                            simcluster[b'simcluster_energy'][simcluster[b'simcluster_eta']<0].flatten()])\n",
    "simclusterEnergyCut = (simcluster_energy_pos_neg > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_simcluster_grtitsn_counts = np.array(list(map(lambda x: x.counts.max(), intersection_pos.flatten())))\n",
    "neg_simcluster_grtitsn_counts = np.array(list(map(lambda x: x.counts.max(), intersection_neg.flatten())))\n",
    "grtitsn_counts = np.concatenate([pos_simcluster_grtitsn_counts, neg_simcluster_grtitsn_counts])\n",
    "fig,axes = plt.subplots(figsize=(12, 7));\n",
    "plotHist(axes, grtitsn_counts[simclusterEnergyCut], \"Rechits\", \"Simclusters\",\\\n",
    "         \"Rechits in Greatest Intersection for each Simcluster\", Nbins = 100)\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcluster_counts = np.concatenate([valid_sim_indices[simcluster[b'simcluster_eta']>0].flatten().counts,\\\n",
    "                valid_sim_indices[simcluster[b'simcluster_eta']<0].flatten().counts])\n",
    "nonzerocut = (simcluster_counts > 0)\n",
    "fig,axes = plt.subplots(figsize=(12, 7));\n",
    "plotHist(axes, grtitsn_counts[simclusterEnergyCut & nonzerocut]/simcluster_counts[simclusterEnergyCut & nonzerocut], \"Ratio\", \"Simclusters\",\\\n",
    "         \"(Rechits in Greatest Intersection for each Simcluster) / (Rechits in Simcluter)\", Nbins = 100)\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_tmp = awkward.JaggedArray.fromcounts(valid_sim_indices.counts,\\\n",
    "                                         list(zip(np.repeat(np.arange(valid_sim_indices.shape[0]),valid_sim_indices.counts), np.concatenate(list(map(np.arange, valid_sim_indices.counts))))))\n",
    "\n",
    "map_posneg2event = np.concatenate([map_tmp[simcluster[b'simcluster_eta']>0].flatten(), map_tmp[simcluster[b'simcluster_eta']<0].flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate these cells to explore Simclusters with low efficiency:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bad_event_list = []\n",
    "for bad_cluster in bad_list:\n",
    "    bad_event_idx = map_posneg2event[bad_cluster][0]\n",
    "    bad_cluster_idx = map_posneg2event[bad_cluster][1]\n",
    "    bad_eta = simcluster[b'simcluster_eta'][bad_event_idx][bad_cluster_idx]\n",
    "    if (np.abs(bad_eta) < 2.2):\n",
    "        \n",
    "        bad_event_list.append(bad_cluster)\n",
    "        \n",
    "bad_event_list = np.array(bad_event_list)\n",
    "bad_event_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "idx_simcluster = 22\n",
    "print(\"Rechits in greatest intersection\", grtitsn_counts[idx_simcluster])\n",
    "print(\"Rechits in simcluster\", simcluster_counts[idx_simcluster])\n",
    "print(\"Ratio/Efficiency\", (grtitsn_counts/simcluster_counts)[idx_simcluster])\n",
    "print(\"Event and simcluster id\", map_posneg2event[idx_simcluster])\n",
    "\n",
    "event_idx = map_posneg2event[idx_simcluster][0]\n",
    "cluster_idx = map_posneg2event[idx_simcluster][1]\n",
    "print(\"Simcluster Eta\", simcluster[b'simcluster_eta'][event_idx][cluster_idx])\n",
    "print(\"Simcluster Energy\", simcluster[b'simcluster_energy'][event_idx][cluster_idx])\n",
    "print(\"Simcluster rechit counts in event\\n\", valid_sim_indices[event_idx].counts)\n",
    "#print(\"Simcluster PID in event\\n\", simcluster[b'simcluster_pid'][event_idx])\n",
    "\n",
    "\n",
    "\n",
    "mask  = rechit[b'rechit_z'][event_idx] > 0.0\n",
    "all_sim_hits = np.unique(valid_sim_indices[event_idx][cluster_idx])\n",
    "sim_hits_mask = np.zeros(rechit[b'rechit_z'][event_idx].size, dtype=np.bool)\n",
    "sim_hits_mask[all_sim_hits] = True\n",
    "simmatched = np.where(sim_hits_mask[mask])[0]\n",
    "\n",
    "g2 = preprocessing_algo(rechit, valid_sim_indices, ievt = event_idx, mask = rechit[b'rechit_z'][event_idx] > 0, layered_norm=layer_norm, algo=grouping_algo, preprocessing_args=preprocessing_args)\n",
    "fig, ax0, ax1 = draw_sample_validation(g2.X,g2.Ri,g2.Ro,g2.y,sim_list=g2.simmatched, particular_simcluster_list=simmatched, skip_false_edges=True)\n",
    "fig.suptitle('simcluster eta: ' + str(simcluster[b'simcluster_eta'][event_idx][cluster_idx]) + \" phi: \" + str(simcluster[b'simcluster_phi'][event_idx][cluster_idx]), fontsize=25);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of Corrected Energy in Greatest Intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grtitsn_pos = intersection_pos.flatten()[awkward.fromiter(map(lambda x: [np.argmax(x.counts)],intersection_pos.flatten()))].flatten()\n",
    "grtitsn_neg = intersection_neg.flatten()[awkward.fromiter(map(lambda x: [np.argmax(x.counts)],intersection_neg.flatten()))].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_grtitsn_pos = rewrap_into_eventCluster_structure(rechit_energy_corrected[awkward.JaggedArray.fromcounts(intersection_pos.counts, grtitsn_pos).flatten(1)].flatten(),\\\n",
    "                                   target_structure = awkward.JaggedArray.fromcounts(intersection_pos.counts, grtitsn_pos))\n",
    "energy_grtitsn_neg = rewrap_into_eventCluster_structure(rechit_energy_corrected[awkward.JaggedArray.fromcounts(intersection_neg.counts, grtitsn_neg).flatten(1)].flatten(),\\\n",
    "                                   target_structure = awkward.JaggedArray.fromcounts(intersection_neg.counts, grtitsn_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.concatenate([energy_grtitsn_pos.flatten().sum(), energy_grtitsn_neg.flatten().sum()])\n",
    "fig = plt.figure(figsize=(18,5));\n",
    "ax1 = fig.add_subplot(121);\n",
    "plotHist(ax1, h[simclusterEnergyCut], \"Sum of Energy in Greatest Intersection / GeV\", \"Simclusters\",\\\n",
    "         \"Sum of Energy in Greatest Intersection for each Simcluter\", Nbins = 100)\n",
    "ax2 = fig.add_subplot(122);\n",
    "plotHist(ax2, h[simclusterEnergyCut]+0.00001, \"Sum of Energy in Greatest Intersection / GeV\", \"Simclusters\",\\\n",
    "         \"Sum of Energy in Greatest Intersection for each Simcluter \\n peak on left indicates 0 GeV\", Nbins = 100, xlog=True)\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcluster_energy_posneg = np.concatenate([corrected_rechit_simcluster_energy[simcluster[b'simcluster_eta']>0].flatten().sum(),\\\n",
    "                                           corrected_rechit_simcluster_energy[simcluster[b'simcluster_eta']<0].flatten().sum()])\n",
    "nonzeromask = (simcluster_energy_posneg > 0)\n",
    "\n",
    "fig = plt.figure(figsize=(19,5));\n",
    "ax1 = fig.add_subplot(121);\n",
    "plotHist(ax1, h[simclusterEnergyCut & nonzeromask]/simcluster_energy_posneg[simclusterEnergyCut & nonzeromask], \"Ratio of Energy\", \"Simclusters\",\\\n",
    "         \"(Sum of energy in Greatest Intersection)/(Sum of energy in Simcluster)\", Nbins = 100)\n",
    "ax2 = fig.add_subplot(122);\n",
    "plotHist(ax2, h[simclusterEnergyCut & nonzeromask]/simcluster_energy_posneg[simclusterEnergyCut & nonzeromask] + 0.00001, \"Ratio of Energy\", \"Simclusters\",\\\n",
    "         \"(Sum of energy in Greatest Intersection)/(Sum of energy in Simcluster) \\n peak on left indicates 0\", Nbins = 100, xlog=True)\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greatest Intersection - First Layer Number  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_grtitsn_pos = rewrap_into_eventCluster_structure((rechit[b'rechit_layer'][awkward.JaggedArray.fromcounts(intersection_pos.counts, grtitsn_pos).flatten(1)]).flatten(),\\\n",
    "                                   target_structure = awkward.JaggedArray.fromcounts(intersection_pos.counts, grtitsn_pos)).flatten()\n",
    "layer_grtitsn_neg = rewrap_into_eventCluster_structure((rechit[b'rechit_layer'][awkward.JaggedArray.fromcounts(intersection_neg.counts, grtitsn_neg).flatten(1)]).flatten(),\\\n",
    "                                   target_structure = awkward.JaggedArray.fromcounts(intersection_neg.counts, grtitsn_neg)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs.append(plotHist_layers(np.concatenate([layer_grtitsn_pos.min(), layer_grtitsn_neg.min()])[simclusterEnergyCut],\\\n",
    "                            \"Simcluster\", \"Greatest Intersection - First Layer Number\", xlabel= \"First Layer Number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greatest Intersection - Last Layer Number  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs.append(plotHist_layers(np.concatenate([layer_grtitsn_pos.max(), layer_grtitsn_neg.max()])[simclusterEnergyCut],\\\n",
    "                            \"Simcluster\", \"Greatest Intersection - Last Layer Number\", xlabel= \"Last Layer Number\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency of Preprocessing Against Eta of Simcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistRatio(axes, dataNumerator, dataNumeratorLabel, dataDenominator, dataDenominatorLabel, xlabel, ylabelNumerator, ylabelDenominator, title, xticks, Nbins = 100, range=None, ylog=False):\n",
    "    fig = plt.figure(figsize=(12,8), constrained_layout=True);\n",
    "    gs = fig.add_gridspec(5, 1)\n",
    "    ax1 = fig.add_subplot(gs[:4, 0])\n",
    "    ax1.set_ylabel(ylabelNumerator)\n",
    "    ax1.set_title(title)\n",
    "    h_numerator, bins,_ = ax1.hist(dataNumerator, bins=Nbins, range=range, histtype='step', log=ylog, label = dataNumeratorLabel); \n",
    "    h_denominator,_,_ = ax1.hist(dataDenominator, bins=bins, range=range, histtype='step', log=ylog, label = dataDenominatorLabel);\n",
    "    plt.legend(loc='upper center')\n",
    "    \n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[4, 0], sharex=ax1);\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    ax2.set_xticks(xticks, minor=True)\n",
    "    ax2.set_ylim((0.0,1.0))\n",
    "    ax2.set_ylabel(ylabelDenominator)\n",
    "    #ax2.plot((bins[:-1] + bins[1:]) / 2, h_numerator / h_denominator)\n",
    "    ax2.bar((bins[:-1] + bins[1:]) / 2, h_numerator / h_denominator, align='center', width=bins[1] - bins[0], fill=False)\n",
    "    plt.grid(True, which='major')\n",
    "    #print((bins[:-1] + bins[1:]) / 2)\n",
    "    return fig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzerocut = (simcluster_counts > 0)\n",
    "efficiency_simcluster_idx = np.where(grtitsn_counts[simclusterEnergyCut & nonzerocut]/simcluster_counts[simclusterEnergyCut & nonzerocut] > 0.9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcluster_eta_pos_neg = np.concatenate([simcluster[b'simcluster_eta'][simcluster[b'simcluster_eta']>0].flatten(),\\\n",
    "simcluster[b'simcluster_eta'][simcluster[b'simcluster_eta']<0].flatten()])\n",
    "\n",
    "fig = plotHistRatio(axes, simcluster_eta_pos_neg[simclusterEnergyCut & nonzerocut][efficiency_simcluster_idx], \"Rechits_Preprocessed/Rechits_Simcluster > 0.9\",\\\n",
    "              simcluster_eta_pos_neg[simclusterEnergyCut & nonzerocut], \"All Simclusters\" , \"Eta\", \"Simclusters\", \"Efficiency\",\\\n",
    "         \"Efficiency against Eta\", Nbins = 100, xticks=np.arange(-3,3,0.1))\n",
    "figs.append(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency of Preprocessing Against Phi of Simcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcluster_phi_pos_neg = np.concatenate([simcluster[b'simcluster_phi'][simcluster[b'simcluster_eta']>0].flatten(),\\\n",
    "simcluster[b'simcluster_phi'][simcluster[b'simcluster_eta']<0].flatten()])\n",
    "\n",
    "fig = plotHistRatio(axes, simcluster_phi_pos_neg[simclusterEnergyCut & nonzerocut][efficiency_simcluster_idx], \"Rechits_Preprocessed/Rechits_Simcluster > 0.9\",\\\n",
    "              simcluster_phi_pos_neg[simclusterEnergyCut & nonzerocut], \"All Simclusters\" , \"Phi\", \"Simclusters\", \"Efficiency\",\\\n",
    "         \"Efficiency against Phi\", Nbins = 100, xticks=np.arange(-3,3,0.1))\n",
    "figs.append(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency of Preprocessing Against Energy of Simcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simcluster_energy_pos_neg = np.concatenate([simcluster[b'simcluster_energy'][simcluster[b'simcluster_eta']>0].flatten(),\\\n",
    "simcluster[b'simcluster_energy'][simcluster[b'simcluster_eta']<0].flatten()])\n",
    "\n",
    "fig = plotHistRatio(axes, simcluster_energy_pos_neg[simclusterEnergyCut & nonzerocut][efficiency_simcluster_idx], \"Rechits_Preprocessed/Rechits_Simcluster > 0.9\",\\\n",
    "              simcluster_energy_pos_neg[simclusterEnergyCut & nonzerocut], \"All Simclusters\" , \"Simcluster Energy\", \"Simclusters\", \"Efficiency\",\\\n",
    "         \"Efficiency against Simcluster Energy\", Nbins = 100, xticks=np.arange(0,100,1.0))\n",
    "figs.append(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "outname = 'validation_preprocessing_' + fname.rstrip('.root').split('/')[-1] +'.pdf'\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(outname)\n",
    "for fig in figs: \n",
    "    pdf.savefig(fig)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
